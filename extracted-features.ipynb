{"cells":[{"cell_type":"code","execution_count":7,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-07-18T17:35:31.428028Z","iopub.status.busy":"2024-07-18T17:35:31.427632Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["<>:6: SyntaxWarning: invalid escape sequence '\\h'\n","<>:6: SyntaxWarning: invalid escape sequence '\\h'\n","C:\\Users\\heman\\AppData\\Local\\Temp\\ipykernel_24952\\1579613164.py:6: SyntaxWarning: invalid escape sequence '\\h'\n","  dataset_folder = 'Users\\heman\\OneDrive\\Documents\\GitHub\\ELC2024'\n","C:\\Users\\heman\\AppData\\Local\\Temp\\ipykernel_24952\\1579613164.py:6: SyntaxWarning: invalid escape sequence '\\h'\n","  dataset_folder = 'Users\\heman\\OneDrive\\Documents\\GitHub\\ELC2024'\n"]},{"ename":"RuntimeError","evalue":"[enforce fail at alloc_cpu.cpp:114] data. DefaultCPUAllocator: not enough memory: you tried to allocate 12937461760 bytes.","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[1;32mIn[7], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m dataset_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mheman\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mOneDrive\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDocuments\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mGitHub\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mELC2024\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# load data\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m dataset_dict \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdataset.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m dataset_dict\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[0;32m     12\u001b[0m x_iq \u001b[38;5;241m=\u001b[39m dataset_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_iq\u001b[39m\u001b[38;5;124m'\u001b[39m]\n","File \u001b[1;32mc:\\Users\\heman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:1026\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1024\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1025\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1026\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1027\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1028\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[43m                     \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1030\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1031\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n\u001b[0;32m   1032\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmmap can only be used with files saved with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1033\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`torch.save(_use_new_zipfile_serialization=True), \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1034\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease torch.save your checkpoint with this option in order to use mmap.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[1;32mc:\\Users\\heman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:1438\u001b[0m, in \u001b[0;36m_load\u001b[1;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1436\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[0;32m   1437\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[1;32m-> 1438\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1440\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[0;32m   1441\u001b[0m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_log_api_usage_metadata(\n\u001b[0;32m   1442\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.load.metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mserialization_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: zip_file\u001b[38;5;241m.\u001b[39mserialization_id()}\n\u001b[0;32m   1443\u001b[0m )\n","File \u001b[1;32mc:\\Users\\heman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:1408\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[1;34m(saved_id)\u001b[0m\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1407\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[1;32m-> 1408\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1410\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n","File \u001b[1;32mc:\\Users\\heman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:1373\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[1;34m(dtype, numel, key, location)\u001b[0m\n\u001b[0;32m   1371\u001b[0m     storage \u001b[38;5;241m=\u001b[39m overall_storage[storage_offset:storage_offset \u001b[38;5;241m+\u001b[39m numel]\n\u001b[0;32m   1372\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1373\u001b[0m     storage \u001b[38;5;241m=\u001b[39m \u001b[43mzip_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_storage_from_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUntypedStorage\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_untyped_storage\n\u001b[0;32m   1374\u001b[0m \u001b[38;5;66;03m# swap here if byteswapping is needed\u001b[39;00m\n\u001b[0;32m   1375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m byteorderdata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at alloc_cpu.cpp:114] data. DefaultCPUAllocator: not enough memory: you tried to allocate 12937461760 bytes."]}],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import torch\n","from torch.utils.data import Dataset\n","\n","dataset_folder = 'Users\\heman\\OneDrive\\Documents\\GitHub\\ELC2024'\n","\n","# load data\n","dataset_dict = torch.load('dataset.pt')\n","dataset_dict.keys()\n","\n","x_iq = dataset_dict['x_iq']\n","x_spec = dataset_dict['x_spec']\n","y = dataset_dict['y']\n","snrs = dataset_dict['snr']\n","duty_cycle = dataset_dict['duty_cycle']"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-07-18T17:18:51.702104Z","iopub.status.busy":"2024-07-18T17:18:51.701309Z","iopub.status.idle":"2024-07-18T17:30:14.210701Z","shell.execute_reply":"2024-07-18T17:30:14.209314Z","shell.execute_reply.started":"2024-07-18T17:18:51.702064Z"},"trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'x_iq' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[8], line 53\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Extracting features and creating DataFrame\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m feature_df \u001b[38;5;241m=\u001b[39m create_feature_dataframe(\u001b[43mx_iq\u001b[49m, x_spec, y, snrs, duty_cycle)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Save to CSV\u001b[39;00m\n\u001b[0;32m     56\u001b[0m feature_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n","\u001b[1;31mNameError\u001b[0m: name 'x_iq' is not defined"]}],"source":["import pandas as pd\n","import numpy as np\n","from scipy.stats import skew, kurtosis\n","from scipy.fft import fft\n","\n","# Function to extract features from spectrograms\n","def extract_spectrogram_features(spectrogram):\n","    mean_val = np.mean(spectrogram)\n","    median_val = np.median(spectrogram)\n","    std_val = np.std(spectrogram)\n","    skewness = skew(spectrogram.flatten())\n","    kurt = kurtosis(spectrogram.flatten())\n","    return [mean_val, median_val, std_val, skewness, kurt]\n","\n","def extract_iq_features(iq_data):\n","    # Assuming iq_data is a 2D array with shape (2, N)\n","    iq_features = []\n","\n","    for channel in iq_data:\n","        mean_val = np.mean(channel)\n","        median_val = np.median(channel)\n","        std_val = np.std(channel)\n","        skewness = skew(channel)\n","        kurt = kurtosis(channel)\n","\n","        # Frequency domain features\n","        freq_domain = fft(channel)\n","        dominant_freq = np.argmax(np.abs(freq_domain))\n","        freq_variance = np.var(np.abs(freq_domain))\n","\n","        iq_features.extend([mean_val, median_val, std_val, skewness, kurt, dominant_freq, freq_variance])\n","\n","    return iq_features\n","\n","# Function to create a DataFrame with extracted features\n","def create_feature_dataframe(x_iq, x_spec, y, snrs, duty_cycle):\n","    features = []\n","    for iq, spec, label, snr, duty in zip(x_iq, x_spec, y, snrs, duty_cycle):\n","        iq = iq.numpy()\n","        spec = spec.numpy()\n","        spectrogram_features = extract_spectrogram_features(spec)\n","        iq_features = extract_iq_features(iq)\n","        features.append(spectrogram_features + iq_features + [snr.item(), duty.item(), label.item()])\n","\n","    columns = ['spec_mean', 'spec_median', 'spec_std', 'spec_skew', 'spec_kurt',\n","               'iq_mean_ch1', 'iq_median_ch1', 'iq_std_ch1', 'iq_skew_ch1', 'iq_kurt_ch1', 'iq_dom_freq_ch1', 'iq_freq_var_ch1',\n","               'iq_mean_ch2', 'iq_median_ch2', 'iq_std_ch2', 'iq_skew_ch2', 'iq_kurt_ch2', 'iq_dom_freq_ch2', 'iq_freq_var_ch2',\n","               'snr', 'duty_cycle', 'label']\n","    df = pd.DataFrame(features, columns=columns)\n","    return df\n","\n","# Extracting features and creating DataFrame\n","feature_df = create_feature_dataframe(x_iq, x_spec, y, snrs, duty_cycle)\n","\n","# Save to CSV\n","feature_df.to_csv('feature_data.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-08T04:22:43.082944Z","iopub.status.busy":"2023-12-08T04:22:43.082261Z","iopub.status.idle":"2023-12-08T04:22:43.091834Z","shell.execute_reply":"2023-12-08T04:22:43.09088Z","shell.execute_reply.started":"2023-12-08T04:22:43.082909Z"},"trusted":true},"outputs":[],"source":["from IPython.display import FileLink\n","FileLink(r'feature_data.csv')"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":3377135,"sourceId":5875011,"sourceType":"datasetVersion"}],"dockerImageVersionId":30497,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":4}
