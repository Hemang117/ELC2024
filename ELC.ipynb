{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np \n",
    "import cv2\n",
    "import os \n",
    "import uuid\n",
    "import time\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\heman/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2024-2-25 Python-3.12.2 torch-2.2.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5l6 summary: 476 layers, 76726332 parameters, 0 gradients, 111.2 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "model=torch.hub.load('ultralytics/yolov5','yolov5l6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame=cap.read()\n",
    "    results=model(frame)\n",
    "    cv2.imshow('MODEL CHECK', np.squeeze(results.render()))\n",
    "\n",
    "    if cv2.waitKey(10) & 0xFF == ord('f'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded to torch data_loader.\n",
      "Loaded a batch of samples from the data loader with batch size 64 and the following shapes:\n",
      "x_iq shape:  torch.Size([64, 2, 16384])\n",
      "x_spec shape:  torch.Size([64, 2, 128, 128])\n",
      "labels shape:  torch.Size([64])\n",
      "snrs shape:  torch.Size([64])\n",
      "duty_cycle shape:  torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "dataset_folder = '/Users/heman/OneDrive/Documents/GitHub/ELC2024/'\n",
    "\n",
    "class DroneSignalsDatasetIQandSpec(Dataset):\n",
    "    \n",
    "    def __init__(self, x_iq_tensor, x_spec_tensor, y_tensor, snr_tensor, duty_cycle_tensor):\n",
    "        self.x_iq = x_iq_tensor\n",
    "        self.x_spec = x_spec_tensor\n",
    "        self.y = y_tensor\n",
    "        self.snr = snr_tensor\n",
    "        self.dury_cyle = duty_cycle_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x_iq[idx], self.x_spec[idx], self.y[idx], self.snr[idx], self.dury_cyle[idx]   \n",
    "\n",
    "    def targets(self):\n",
    "        return self.y \n",
    "\n",
    "    def snrs(self):\n",
    "        return self.snr\n",
    "\n",
    "    def duty_cycle(self):\n",
    "        return self.duty_cycle\n",
    "\n",
    "\n",
    "def plot_input_data(spectrogram_2d, iq_2d, title='', figsize=(10,9)):\n",
    "\n",
    "    fig, axs = plt.subplot_mosaic([['spec_re', 'spec_im'], ['spec_re', 'spec_im'], ['iq_re', 'iq_re'], ['iq_im', 'iq_im']], figsize=figsize) # layout='constrained'\n",
    "    \n",
    "    # plot spectrogram Re and Im\n",
    "    spec_re = axs['spec_re'].imshow(spectrogram_2d[0,:,:]) #, aspect='auto', origin='lower')\n",
    "    axs['spec_re'].set_title('Re', fontsize=10)\n",
    "    fig.colorbar(spec_re, ax=axs['spec_re'], location='right', shrink=0.5)\n",
    "\n",
    "    spec_im = axs['spec_im'].imshow(spectrogram_2d[1,:,:]) #, aspect='auto', origin='lower')\n",
    "    axs['spec_im'].set_title('Im', fontsize=10)\n",
    "    fig.colorbar(spec_im, ax=axs['spec_im'], location='right', shrink=0.5)\n",
    "\n",
    "    # plot iq Re and Im\n",
    "    axs['iq_re'].plot(iq_2d[0,:])\n",
    "    axs['iq_re'].set_title('IQ data')\n",
    "    axs['iq_re'].set_ylabel('Re', rotation=0)\n",
    "\n",
    "    axs['iq_im'].plot(iq_2d[1,:])\n",
    "    # axs['iq_im'].set_title('Im')\n",
    "    axs['iq_im'].set_xlabel('Time (samples)')\n",
    "    axs['iq_im'].set_ylabel('Im', rotation=0)\n",
    "    \n",
    "    # add figure title\n",
    "    fig.suptitle(plt_title + '\\n\\nSpectrogram')\n",
    "    plt.savefig('sample_input_data.png', dpi=300, bbox_inches='tight')   \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# read statistics/class count of the dataset\n",
    "dataset_stats = pd.read_csv(dataset_folder + 'class_stats.csv', index_col=0)\n",
    "class_names = dataset_stats['class'].values\n",
    "\n",
    "# read SNR count of the dataset\n",
    "snr_stats = pd.read_csv(dataset_folder + 'SNR_stats.csv', index_col=0)\n",
    "snr_list = snr_stats['SNR'].values\n",
    "\n",
    "# load data\n",
    "dataset_dict = torch.load(dataset_folder + 'dataset.pt')\n",
    "dataset_dict.keys()\n",
    "\n",
    "x_iq = dataset_dict['x_iq']\n",
    "x_spec = dataset_dict['x_spec']\n",
    "y = dataset_dict['y']\n",
    "snrs = dataset_dict['snr']\n",
    "duty_cycle = dataset_dict['duty_cycle']\n",
    "\n",
    "# create pytorch dataset form tensors\n",
    "dataset = DroneSignalsDatasetIQandSpec(x_iq,x_spec,y,snrs,duty_cycle)\n",
    "del(x_iq, x_spec, y, snrs, duty_cycle, dataset_dict)\n",
    "\n",
    "# define a data loader\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=64)\n",
    "\n",
    "print('Dataset loaded to torch data_loader.')\n",
    "\n",
    "# get a batch of samples from the data loader\n",
    "x_iq, x_spec, labels, snrs, duty_cycle =  next(iter(data_loader))\n",
    "x_iq.shape, x_spec.shape, labels.shape, snrs.shape, duty_cycle.shape\n",
    "\n",
    "print('Loaded a batch of samples from the data loader with batch size', x_iq.shape[0], 'and the following shapes:')\n",
    "print('x_iq shape: ', x_iq.shape)\n",
    "print('x_spec shape: ', x_spec.shape)\n",
    "print('labels shape: ', labels.shape)\n",
    "print('snrs shape: ', snrs.shape)\n",
    "print('duty_cycle shape: ', duty_cycle.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a sample from the batch\n",
    "sample_id = 52\n",
    "\n",
    "# plot the sample\n",
    "act_snr = snrs[sample_id]\n",
    "act_duty_cycle = duty_cycle[sample_id]\n",
    "act_class = class_names[labels[sample_id]]\n",
    "plt_title = 'Class: ' + act_class + ', SNR: ' + str(act_snr.numpy()) + 'dB, Duty Cycle: ' + str(act_duty_cycle.numpy())\n",
    "\n",
    "spectrogram_2d = x_spec[sample_id,:,:,:]\n",
    "iq_2d = x_iq[sample_id,:,:]\n",
    "plot_input_data(spectrogram_2d, iq_2d, title=plt_title, figsize=(10,7))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 53\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Extracting features and creating DataFrame\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m feature_df \u001b[38;5;241m=\u001b[39m create_feature_dataframe(x_iq, x_spec, \u001b[43my\u001b[49m, snrs, duty_cycle)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Save to CSV\u001b[39;00m\n\u001b[0;32m     56\u001b[0m feature_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.fft import fft\n",
    "\n",
    "# Function to extract features from spectrograms\n",
    "def extract_spectrogram_features(spectrogram):\n",
    "    mean_val = np.mean(spectrogram)\n",
    "    median_val = np.median(spectrogram)\n",
    "    std_val = np.std(spectrogram)\n",
    "    skewness = skew(spectrogram.flatten())\n",
    "    kurt = kurtosis(spectrogram.flatten())\n",
    "    return [mean_val, median_val, std_val, skewness, kurt]\n",
    "\n",
    "def extract_iq_features(iq_data):\n",
    "    # Assuming iq_data is a 2D array with shape (2, N)\n",
    "    iq_features = []\n",
    "\n",
    "    for channel in iq_data:\n",
    "        mean_val = np.mean(channel)\n",
    "        median_val = np.median(channel)\n",
    "        std_val = np.std(channel)\n",
    "        skewness = skew(channel)\n",
    "        kurt = kurtosis(channel)\n",
    "\n",
    "        # Frequency domain features\n",
    "        freq_domain = fft(channel)\n",
    "        dominant_freq = np.argmax(np.abs(freq_domain))\n",
    "        freq_variance = np.var(np.abs(freq_domain))\n",
    "\n",
    "        iq_features.extend([mean_val, median_val, std_val, skewness, kurt, dominant_freq, freq_variance])\n",
    "\n",
    "    return iq_features\n",
    "\n",
    "# Function to create a DataFrame with extracted features\n",
    "def create_feature_dataframe(x_iq, x_spec, y, snrs, duty_cycle):\n",
    "    features = []\n",
    "    for iq, spec, label, snr, duty in zip(x_iq, x_spec, y, snrs, duty_cycle):\n",
    "        iq = iq.numpy()\n",
    "        spec = spec.numpy()\n",
    "        spectrogram_features = extract_spectrogram_features(spec)\n",
    "        iq_features = extract_iq_features(iq)\n",
    "        features.append(spectrogram_features + iq_features + [snr.item(), duty.item(), label.item()])\n",
    "\n",
    "    columns = ['spec_mean', 'spec_median', 'spec_std', 'spec_skew', 'spec_kurt',\n",
    "               'iq_mean_ch1', 'iq_median_ch1', 'iq_std_ch1', 'iq_skew_ch1', 'iq_kurt_ch1', 'iq_dom_freq_ch1', 'iq_freq_var_ch1',\n",
    "               'iq_mean_ch2', 'iq_median_ch2', 'iq_std_ch2', 'iq_skew_ch2', 'iq_kurt_ch2', 'iq_dom_freq_ch2', 'iq_freq_var_ch2',\n",
    "               'snr', 'duty_cycle', 'label']\n",
    "    df = pd.DataFrame(features, columns=columns)\n",
    "    return df\n",
    "\n",
    "# Extracting features and creating DataFrame\n",
    "feature_df = create_feature_dataframe(x_iq, x_spec, y, snrs, duty_cycle)\n",
    "\n",
    "# Save to CSV\n",
    "feature_df.to_csv('feature_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
